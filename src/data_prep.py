'''
    data_prep.py contains:
        (1) Class IoT_Device loads data from the datasets
        (2) Runs prediction models:
            a) LogisticRegression
'''
import os
import sys
sys.path.append("../")
import pandas as pd
import numpy as np
import pickle
from sklearn.utils import resample
from sklearn.dummy import DummyClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, RandomizedSearchCV
from sklearn.impute import SimpleImputer
from sklearn.decomposition import PCA
from sklearn.neighbors import KNeighborsClassifier
from xgboost import XGBClassifier
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.metrics import confusion_matrix, classification_report
from yellowbrick.classifier import ClassificationReport # conda install -c districtdatalabs yellowbrick
from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor
from sklearn.pipeline import Pipeline
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import plot_confusion_matrix, roc_curve, auc
from sklearn import metrics


from xgboost import XGBClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import BaggingClassifier, RandomForestClassifier
from sklearn.naive_bayes import GaussianNB

import matplotlib.pyplot as plt
import seaborn as sns
sns.set(font_scale=1.5)
from datetime import datetime
from src.data_constants import *

import itertools

def yes_or_no(question):
    '''
        Utility Function to get a response back y or n
    '''
    answer = input(question + "(y/n): ").lower().strip()
    print("")
    while not(answer == "y" or answer == "yes" or \
    answer == "n" or answer == "no"):
        print("Input yes or no")
        answer = input(question + "(y/n):").lower().strip()
        print("")
    if answer[0] == "y":
        return True
    else:
        return False

def read_device_pickle(iot_device_num):
    """
        Function: read_device_pickle
        input: device_number 
        Action: If a pickle file of the device object exsist in data_prep directory 
                deserialize iot object and return or return None
    """
    
    file_name = '../../data_prep/'+IOT_DEVICES[iot_device_num][2]+".pkl"
    print(file_name)
    if os.path.exists(file_name):
        pickle_file = open(file_name, 'rb')
        iot = pickle.load(pickle_file)
        pickle_file.close()
    else:
        iot = None
    return iot

def write_device_pickle(iot_class_obj, iot_device_num):
    """
        Function: write_device_pickle
        input: iot_ckass object, iot_device_num
        Action: Create a pickle file of the object and store it in data_prep directory 
        Return: None
    """
    # create a pickle file
    pkl_file_name = '../../data_prep/'+IOT_DEVICES[iot_device_num][2]+".pkl"
    pickle_file = open(pkl_file_name, 'wb')
    
    # pickle iot object for the device and write to it.
    pickle.dump(iot_class_obj, pickle_file)
    pickle_file.close()
    

def timer(start_time=None):
    """
        Function: Utility function for timing opearations. 
        Input: None -> to start the timer
               start_time -> stop the timer
    """
    if not start_time:
        start_time = datetime.now()
        return start_time
    elif start_time:
        thour, temp_sec = divmod((datetime.now() - start_time).total_seconds(), 3600)
        tmin, tsec = divmod(temp_sec, 60)
        print('\n Time taken: %i hours %i minutes and %s seconds.' % (thour, tmin, round(tsec, 2)))
    
def list_iot_devices():
    """
        Function: Utility function to list IoT devices 
    """
    # List of all IoT devices for which data was collcted
    device_list = {"Door_Bell": {"Damini_Doorbell":1, "Ennino_Doorbell":2},
               "Thermostats": {"Ecobee_Thermostat":1},
               "Baby_Monitor": {"Philips_B120N10_Baby_Monitor":1},
               "Security_Camera": {"Provision_PT_737E_Security_Camera":1,
                                   "Provision_PT_838_Security_Camera":2,
                                   "SimpleHome_XCS7_1002_WHT_Security_Camera":3,
                                   "SimpleHome_XCS7_1003_WHT_Security_Camera":4}}
   
    print("{:<17} {:<41} {:<60}".format('_______________','________________________________________','______'))
    print("{:<17} {:<41} {:<60}".format('Decice Category','Device','Number'))
    print("{:<17} {:<41} {:<60}".format('_______________','________________________________________','______'))
    
    for device,iots in device_list.items():
        for iot,val in device_list[device].items():
            print("{:<17} {:<41} {:<60}".format(device, iot, val)) 
    return device_list

def make_confusion_matrix(cf,
              group_names=None,
              categories='auto',
              count=True,
              percent=True,
              cbar=True,
              xyticks=True,
              xyplotlabels=True,
              sum_stats=True,
              figsize=None,
              cmap='coolwarm',
              title=None):
    '''
    This function will make a pretty plot of an sklearn Confusion Matrix cm using a Seaborn heatmap visualization.
    Arguments
    ---------
    cf:            confusion matrix to be passed in
    group_names:   List of strings that represent the labels row by row to be shown in each square.
    categories:    List of strings containing the categories to be displayed on the x,y axis. Default is 'auto'
    count:         If True, show the raw number in the confusion matrix. Default is True.
    normalize:     If True, show the proportions for each category. Default is True.
    cbar:          If True, show the color bar. The cbar values are based off the values in the confusion matrix.
                   Default is True.
    xyticks:       If True, show x and y ticks. Default is True.
    xyplotlabels:  If True, show 'True Label' and 'Predicted Label' on the figure. Default is True.
    sum_stats:     If True, display summary statistics below the figure. Default is True.
    figsize:       Tuple representing the figure size. Default will be the matplotlib rcParams value.
    cmap:          Colormap of the values displayed from matplotlib.pyplot.cm. Default is 'Blues'
                   See http://matplotlib.org/examples/color/colormaps_reference.html
                   
    title:         Title for the heatmap. Default is None.
    '''


    # CODE TO GENERATE TEXT INSIDE EACH SQUARE
    blanks = ['' for i in range(cf.size)]

    if group_names and len(group_names)==cf.size:
        group_labels = ["{}\n".format(value) for value in group_names]
    else:
        group_labels = blanks

    if count:
        group_counts = ["{0:0.0f}\n".format(value) for value in cf.flatten()]
    else:
        group_counts = blanks

    if percent:
        group_percentages = ["{0:.3%}".format(value) for value in cf.flatten()/np.sum(cf)] #.2->.3
    else:
        group_percentages = blanks

    box_labels = [f"{v1}{v2}{v3}".strip() for v1, v2, v3 in zip(group_labels,group_counts,group_percentages)]
    box_labels = np.asarray(box_labels).reshape(cf.shape[0],cf.shape[1])


    # Generate Summary Stats
    if sum_stats:
        #Accuracy is sum of diagonal divided by total observations
        accuracy  = np.trace(cf) / float(np.sum(cf))

        #if it is a binary confusion matrix, show some more stats
        if len(cf)==2:
            #Metrics for Binary Confusion Matrices
            precision = cf[1,1] / sum(cf[:,1])
            recall    = cf[1,1] / sum(cf[1,:])
            f1_score  = 2*precision*recall / (precision + recall)
            stats_text = "\n\nAccuracy={:0.3f}\nPrecision={:0.3f}\nRecall={:0.3f}\nF1 Score={:0.3f}".format(
                accuracy,precision,recall,f1_score)
        else:
            stats_text = "\n\nAccuracy={:0.3f}".format(accuracy)
    else:
        stats_text = ""


    # SET FIGURE PARAMETERS ACCORDING TO OTHER ARGUMENTS
    if figsize==None:
        #Get default figure size if not set
        figsize = plt.rcParams.get('figure.figsize')

    if xyticks==False:
        #Do not show categories if xyticks is False
        categories=False


    # MAKE THE HEATMAP VISUALIZATION
    fig = plt.figure(figsize=figsize)
    sns.heatmap(cf,annot=box_labels,fmt="",cmap=cmap,cbar=cbar,xticklabels=categories,yticklabels=categories)
        
    if xyplotlabels:
        plt.ylabel('True label')
        plt.xlabel('Predicted label' + stats_text)
    else:
        plt.xlabel(stats_text)
    
    if title:
        plt.title(title)
    fig.savefig("../../visualization/"+title+".png")
    plt.show()
    

class IoT_Device:
    '''
        Class: IoT_Device
        Usage: Instantiate an object for each device which will hold data and save
               key attributes in the object and pickled. This object can be used to quickly run
               models after reading pickle file for any given IoT device

    '''   
    def __init__(self,device):  
        
        global IOT_DEVICES

        self.y = None
        self.X = None
        self.device_type = IOT_DEVICES[device][0]
        self.device_num = IOT_DEVICES[device][1]
        self.device_name = IOT_DEVICES[device][2]      
        self.device = device   
        self.iot_dataframe(self.device_name)

    def create_df (self, filename):
        '''
            Method: Create_df
            Input: filename, device
            Action: Read filename and return datafram
        '''
   
    def iot_read_botnet_file(self, filename):
        '''
            Action: Read filename and return Dash dataframe        
        '''
        df = pd.DataFrame()
        if os.path.exists(filename):
            df = pd.read_csv(filename)
            file_found = True
        else:
            print("File Missing: ", filename)
            file_found = False
        return df, file_found
    
    def iot_accuracy(self,  confusion_matrix):
        '''
            Calculate Accuracy of multi-class model from the confution matrix.
        '''
        diagonal_sum = confusion_matrix.trace()
        sum_of_all_elements = confusion_matrix.sum()
        return diagonal_sum / sum_of_all_elements 

    def iot_recall(self, label, confusion_matrix):
        '''
            Calculate Recall of multi-class model from the confution matrix.
        '''
        row = confusion_matrix[label, :]
        return confusion_matrix[label, label] / row.sum()
    
    def iot_precision(self, label, confusion_matrix):
        '''
            Calculate Precision of multi-class model from the confution matrix.
        '''
        col = confusion_matrix[:, label]
        return confusion_matrix[label, label] / col.sum()
    
    def iot_recall_macro_average(self, confusion_matrix):
        '''
            Calculate 'macro_recall' of multi-class model from the confution matrix.
        '''
        rows, columns = confusion_matrix.shape
        sum_of_recalls = 0
        for label in range(columns):
            sum_of_recalls += self.iot_recall(label, confusion_matrix)
        return sum_of_recalls / columns    

    def iot_model_score(self,cm, model):
        '''
            Calculate Scores of multi-class model from the confution matrix.
        '''        
        self.model_score = {'Device': self.device_name, 
                      'Model': model,
                      'Recall_0': 0.00, 
                      'Recall_1': 0.00, 
                      'Recall_2': 0.00,
                      'Macro_Recall': 0.00,
                      'Accuracy': self.iot_accuracy(cm)}  

        lst = np.unique(self.y)
        self.model_score['Recall_0'] = self.iot_recall(0,cm)
        if len(lst) == 3:
            self.model_score['Recall_1'] = self.iot_recall(1,cm)
            self.model_score['Recall_2'] = self.iot_recall(2,cm)    
        elif  1 in lst: sel.model_score['Recall_1'] = self.iot_recall(1,cm) 
        else:  self.model_score['Recall_2'] = self.iot_recall(1,cm)                    

        self.model_score['Macro_Recall'] = self.iot_recall_macro_average(cm)

        return self.model_score

    def iot_xgboost_hyperparameter_tuning(self, which_score):
        '''
            Method Name: iot_xgboost_hyperparameter_tuning
            Input: self
            Returns: None
            Because I have a large dataset, let me put some timer while running parameter turning
            Loop through each of the 9 IoT devices to score on Recall.
        '''
        print("inside")
        print("which_score", which_score)
        ## Hyper Parameter Optimization Selection
        params={
         "learning_rate"    : [0.05, 0.10, 0.15, 0.20, 0.25, 0.30 ] ,
         "max_depth"        : [ 3, 4, 5, 6, 8, 10, 12, 15],
         "min_child_weight" : [ 1, 3, 5, 7 ],
         "gamma"            : [ 0.0, 0.1, 0.2 , 0.3, 0.4 ],
         "colsample_bytree" : [ 0.3, 0.4, 0.5 , 0.7 ]}

        # Instantiate XGBClassifer()
        xgb = XGBClassifier()
        if which_score == 'recall':
            random_search = RandomizedSearchCV(xgb,param_distributions=params,n_iter=5,scoring='recall_macro',  n_jobs=-1,cv=5,verbose=3)
        else:
            random_search = RandomizedSearchCV(xgb,param_distributions=params,n_iter=5,scoring='accuracy',  n_jobs=-1,cv=5,verbose=3)

        # Start the timer and for fit 
        start_time = timer(None) 
        random_search.fit(self.X,self.y)
        
        # End the timer
        timer(start_time) 

        print("\nbest_estimator_:", random_search.best_estimator_)
        print("\nbest_params_:", random_search.best_params_)

        score=cross_val_score(xgb, self.X,self.y,cv=10)
        print("Score: ", score)
        if which_score == 'recall':
            print("\XGBoost - Mean of Macro Recall scores:",score.mean())
        else:
            print("\nXGBoost - Mean of Accuracy scores: ", score.mean())


    def iot_randomforest_hyperparameter_tuning(self, which_score):
        '''
            Method Name: iot_randomforest_hyperparameter_tuning
            Input: self
            Returns: None
            Because I have a large dataset, let me put some timer while running parameter turning
            Loop through each of the 9 IoT devices to score on Recall.
        '''
            
        # Hyper Parameter Optimization Selection
        which_score = "recall"
        params = {"n_estimators": [100,300,500,700, 900, 1000],
                     "criterion": ["gini", "entropy"],
                     "max_depth": [ 3,  5,  10, None], 
                     "max_features": ["auto", "sqrt"] }


        # Instantiate RandomForestClassifer()
        rfc= RandomForestClassifier( n_jobs=-1, oob_score = False, random_state=42)

        if which_score == 'recall':
            random_search = RandomizedSearchCV(rfc,param_distributions=params,n_iter=5,scoring='recall_macro', n_jobs=-1,cv=5,verbose=3)
        else:
            random_search = RandomizedSearchCV(rfc,param_distributions=params,n_iter=5,scoring='accuracy', n_jobs=-1,cv=5,verbose=3)


        # Start the timer and for fit 
        start_time = timer(None) 
        random_search.fit(self.X,self.y)

        # End the timer
        timer(start_time) 

        print("\nbest_estimator_: ", random_search.best_estimator_)
        print("\nbest_params_: ", random_search.best_params_)

        score=cross_val_score(rfc,self.X, self.y,cv=10)
        print("RF: Score: ", score)
        if which_score == 'recall':
            print("\nRF: Mean of Recall scores:",score.mean())
        else:
            print("\nRF: Mean of Accuracy scores:",score.mean())
    
    def iot_dataframe(self, device_name):
        '''
            Method: iot_dataframe
            Input: device_name (sring)
            Usage: This is the key for data preaparation and data engineering
        '''

        device_type = self.device_type   # IOT_device_type
        device_num = self.device_num
        device_name = self.device_name

        # Read benign traffic for the device
        benign_data_file = "../../data/"+ device_name +"/benign_traffic.csv"

        # Create empty dask dataframes 
        df_all = pd.DataFrame()
        df_benign = pd.DataFrame()
        df_mirai = pd.DataFrame()
        df_gafgyt = pd.DataFrame()
        df_temp = pd.DataFrame()

        #Benign dataframe
        df_temp,ff = self.iot_read_botnet_file(benign_data_file)
        df_temp['Class'] = BENIGN
        df_temp['Device'] = device_num
        df_temp["Device_Type"] = device_type
        df_temp["Traffic_Type"] = BENIGN

        # Append benign dataframe for this device to a huge benign dataframe
        df_benign = df_benign.append(df_temp)

        '''
            For the device, create mirai dataframes for ack, scan, syn, udp, 
            udpplain attack dataframes
        '''
        # Mirai file path for each device
        mirai_path = "../../data/"+ device_name +"/mirai_attacks/"

        # 1. ack.csv
        fn = mirai_path+"ack.csv"
        df_temp, ff = self.iot_read_botnet_file(fn)
        if ff: 
            df_temp['Class'] = MIRAI
            df_temp["Device"] = device_num
            df_temp["Device_Type"] = device_type
            df_temp["Traffic_Type"] = MIRAI_ACK
            df_mirai = df_mirai.append(df_temp)
        #2 scan.csv    
        fn = mirai_path+"scan.csv"
        df_temp, ff = self.iot_read_botnet_file(fn)
        if ff: 
            df_temp['Class'] = MIRAI
            df_temp['Device'] = device_num
            df_temp['Device_Type'] = device_type
            df_temp['Traffic_Type'] = MIRAI_SCAN
            df_mirai = df_mirai.append(df_temp)       

        #3 syn.csv    
        fn = mirai_path+"syn.csv"        
        df_temp, ff = self.iot_read_botnet_file(fn)       
        if ff: 
            df_temp['Class'] = MIRAI
            df_temp["Device"] = device_num
            df_temp["Device_Type"] = device_type
            df_temp["Traffic_Type"] = MIRAI_SYN
            df_mirai = df_mirai.append(df_temp)

        #4 udp.csv    
        fn = mirai_path+"udp.csv"
        df_temp, ff = self.iot_read_botnet_file(fn) 
        if ff: 
            df_temp['Class'] = MIRAI
            df_temp["Device"] = device_num
            df_temp["Device_Type"] = device_type
            df_temp["Traffic_Type"] = MIRAI_UDP
            df_mirai = df_mirai.append(df_temp)

        #5 udpplain.csv    
        fn = mirai_path+"udpplain.csv"
        df_temp,ff  = self.iot_read_botnet_file(fn) 
        if ff: 
            df_temp['Class'] = MIRAI
            df_temp["Device"] = device_num
            df_temp["Device_Type"] = device_type
            df_temp["Traffic_Type"] = MIRAI_UDPPLAIN
            df_mirai = df_mirai.append(df_temp)
            
        '''
            For the device, create gafgyt attack dataframes for combo, junk, scan, tcp and udp attack dataframes
        '''
        gafgyt_path = "../../data/"+ device_name +"/gafgyt_attacks/"

        # 1. combo.csv
        fn = gafgyt_path+"combo.csv"
        df_temp, ff = self.iot_read_botnet_file(fn) 
        if ff: 
            df_temp['Class'] = BASHLITE
            df_temp["Device"] = device_num
            df_temp["Device_Type"] = device_type
            df_temp["Traffic_Type"] = BASHLITE_COMBO
            df_gafgyt = df_gafgyt.append(df_temp)

        #2 junk.csv    
        fn = gafgyt_path+"junk.csv"

        df_temp,ff = self.iot_read_botnet_file(fn) 
        if ff: 
            df_temp['Class'] = BASHLITE
            df_temp["Device"] = device_num
            df_temp["Device_Type"] = device_type
            df_temp["Traffic_Type"] = BASHLITE_JUNK
            df_gafgyt = df_gafgyt.append(df_temp)

        #3 scan.csv    
        fn = gafgyt_path+"scan.csv"
        df_temp, ff = self.iot_read_botnet_file(fn) 
        if ff: 
            df_temp['Class'] = BASHLITE
            df_temp["Device"] = device_num
            df_temp["Device_Type"] = device_type
            df_temp["Traffic_Type"] = BASHLITE_SCAN
            df_gafgyt = df_gafgyt.append(df_temp)

        #4 tcp.csv    
        fn = gafgyt_path+"tcp.csv"
        df_temp, ff = self.iot_read_botnet_file(fn) 
        if ff: 
            df_temp['Class'] = BASHLITE
            df_temp["Device"] = device_num
            df_temp["Device_Type"] = device_type
            df_temp["Traffic_Type"] = BASHLITE_TCP
            df_gafgyt = df_gafgyt.append(df_temp)

        #5 udp.csv    
        fn = gafgyt_path+"udp.csv"
        df_temp,ff = self.iot_read_botnet_file(fn) 
        if ff: 
            df_temp['Class'] = BASHLITE
            df_temp["Device"] = device_num
            df_temp["Device_Type"] = device_type
            df_temp["Traffic_Type"] = BASHLITE_UDP
            df_gafgyt = df_gafgyt.append(df_temp)
                  
        
        # Becasuse we have a large dataset, I will select the minimum number of observations and select from each
        benign_rows = df_benign.shape[0]
        mirai_rows = df_mirai.shape[0]
        gafgyt_rows = df_gafgyt.shape[0]        
        select_rows = min([int(cnt) for cnt in [benign_rows, mirai_rows, gafgyt_rows] if cnt>0])

        # Randomly select observtions from each datasetÎ©
        if benign_rows > 0: df_benign = df_benign.sample(n=select_rows, replace=False, random_state=42)
        if mirai_rows > 0:  df_mirai = df_mirai.sample(n=select_rows, replace=False, random_state=42)
        if gafgyt_rows > 0: df_gafgyt = df_gafgyt.sample(n=select_rows, replace=False, random_state=42)
        
        # Create a combinded dataset and shuffle
        df_all = pd.concat([df_benign, df_mirai, df_gafgyt], ignore_index=True)
        df_all = df_all.sample(frac=1).reset_index(drop=True) 
        
        # Select columns relevant for modeling. 
        # Rest are mean, variance, covariance and other statistical measurea of the selected features, so drop them
        self.X = df_all[['H_L5_weight', 'H_L3_weight', 'H_L1_weight', 'H_L0.1_weight', 'H_L0.01_weight', 
                        'HH_L5_weight','HH_L3_weight', 'HH_L1_weight', 'HH_L0.1_weight', 'HH_L0.01_weight', 
                        'HH_jit_L5_weight', 'HH_jit_L3_weight','HH_jit_L1_weight','HH_jit_L0.1_weight', 'HH_jit_L0.01_weight']]        
        self.y = df_all['Class']


        self.device_type = device_type
        self.device_num = device_num
        self.device_name = device_name
        
        print("Ready to pickle the device ..  Shape: {}".format(len(self.y))) 

    def iot_confusion_matrix(self, print_train, y_test, y_hat_test, title_test, y_train=None, y_hat_train=None, title_train=None):
        '''
            This method will print confustion matrix for both train and test sets
        '''
        cm_train = cm_test = None       

        # Run confustion_matric with the predicted value and the test set
        if print_train == True:
            # print classification report
            print("\n***** " + title_train + " *****\n")
            print(classification_report(y_train, y_hat_train, digits=3))
            
            # Check if the target has 2 or 3 classes and label it accordingly
            cat_list = ["Benign" if cl==0 else "Mirai" if cl==1 else "gafgyt"  for cl in np.unique(y_train)]            
            cm_train = confusion_matrix(y_train, y_hat_train) 
            make_confusion_matrix(cm_train, figsize=(8,6), categories=cat_list, cbar=False, title=title_train, sum_stats=True)

#         # Run confustion_matric with the predicted value and the test set
#         cm_test = confusion_matrix(y_test, y_hat_test)
        
        # Check if the target has 2 or 3 classes and label it accordingly
        cat_list = ["Benign" if cl==0 else "Mirai" if cl==1 else "gafgyt"  for cl in np.unique(y_test)] 
        print("\n***** " + title_test + " *****\n")
        print(classification_report(y_test, y_hat_test, digits=3))
        cm_test = confusion_matrix(y_test, y_hat_test) 
        make_confusion_matrix(cm_test, figsize=(8,6), categories=cat_list, cbar=False, title=title_test, sum_stats=True)
        
        return cm_test, cm_train


    
    def iot_roc_curve(self, fpr, tpr, title):
        '''
            Method: iot_roc_curve
            Input: x-values(False Positive) and y-values(True Positive)
            
        '''
        
        # Seaborn's beautiful styling
        sns.set_style('darkgrid', {'axes.facecolor': '0.9'})

        print('AUC: {}'.format(auc(fpr, tpr)))
        plt.figure(figsize=(10, 8))
        lw = 2
        plt.plot(fpr, tpr, color='darkorange',
                 lw=lw, label='ROC curve')
        plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')
        plt.xlim([0.0, 1.0])
        plt.ylim([0.0, 1.05])
        plt.yticks([i/20.0 for i in range(21)])
        plt.xticks([i/20.0 for i in range(21)])
        plt.xlabel('False Positive Rate')
        plt.ylabel('True Positive Rate')
        plt.title(title)
        plt.legend(loc='lower right')
        plt.show()
                                                
    def iot_Fit_Predict_Report(self, model, model_name,  X_train, X_val, y_train, y_val):
        '''
            Method: iot_Fit_Predict
            Input: model, model_name, X_train, X_val, y_train, y_val
            Usage: Run the model and create confusion matrix charts
        '''
        # Fit Model
        model.fit(X_train, y_train)
        
        # Predict and Report
        y_hat_train = model.predict(X_train)
        y_hat_val = model.predict(X_val)
        
        # print confustion_matric with the predicted values for train data and val data
        title_val = "[" + self.device_name + "] [Validation Data] " + model_name
        title_train ="[" + self.device_name + "] [Train Data] " + model_name

        # Store the model and results as a class variable
        test_cm, train_cm = self.iot_confusion_matrix( True, y_val, y_hat_val, title_val, y_train, y_hat_train, title_train )       
        
        return  train_cm, test_cm, y_hat_train, y_hat_val
        
    def iot_Model(self, model_name): 
        '''
            IoT_FSM method will perform a first simple model with LogisticRegression with all default parameters, except max_iter=1000 otherwise cpu is going crazy
            
            Method: IoT_FSM
            Input: "FSM", "LogisticRegression", "KNeighborsClassifier", "DecisionTreeClassifier", "RandomForestClassifer"
            Action: 1) Change target to binary, for FSM only.
                    2) Instantiate LogisticRegression classifier
                    3) Fit model
                    4) Run cross_val_score
        '''   
        if model_name == "DummyClassifier":
            '''
                DummyClassifier is a classifier that makes predictions using simple rules.
                This classifier is useful as a simple baseline to compare with other (real) classifiers.
                Use of strategy 'stratified' reflects the use of the class distribution
            '''
            dummy_model = DummyClassifier(strategy="stratified", random_state=42)
            dummy_model.fit(self.X, self.y)
            y_hat = dummy_model.predict(self.X)
            
            # print classification report to out put recall, precision, accuacy and F1 scores
            print(classification_report(self.y, y_hat, digits=3))
                    
            self.dummy_model_cross_val_score = cross_val_score(dummy_model, self.X, self.y, cv=5)
            print(f"\n [{self.device}] Dummy Model: Raw Input Data--cross_val_score-", self.dummy_model_cross_val_score)
            title_test = "[" + self.device_name + "] [Test Data] "+ model_name
            title_train=""
            
            self.dummy_test_cm, self.dummy_train_cm = self.iot_confusion_matrix(False, self.y, y_hat, title_test, None, None, None)       

        elif model_name == "FSM":
            '''
                For First Simple Model, we will LogisticRegression.
                However, we will use the entire dataset without split.
            '''
            ss = StandardScaler()
            X_ss = ss.fit_transform(self.X)
            
            fsm = LogisticRegression()
            fsm.fit(X_ss,self.y)
            
            y_hat = fsm.predict(self.X)
            
            title_test = "[" + self.device_name + "] [Test Data] FSM-LogisticRegression"
            title_train =""
            
            # print classification report to out put recall, precision, accuacy and F1 scores
            print(classification_report(self.y, y_hat, digits=3))  
            
            # Call iot_confusion_matrix  to print confustion matrix
            self.fsm_test_cm, self.fsm_train_cm = self.iot_confusion_matrix(False, self.y, y_hat, title_test, None, None, None)
            self.fsm_model = fsm                      
            
            # Cross Validation Score
            self.fsm_cross_val_score = cross_val_score(fsm, self.X, self.y, cv=5)
            print(f"\n [{self.device}] FSM Model: Raw Input Data--cross_val_score-", self.fsm_cross_val_score)           

        else:           
                    '''
                        We will do the following here.
                        1) Split the data and keep aside 30% if test data for final testing.
                        2) Do a secondary split on the remaining 70% data with train and validation dataset for model turning.
                    '''                   
                    
                
                    # Train test split - to hold out 30% of test data for validating the model
                    X_train, X_test, y_train, y_test = train_test_split(self.X, self.y, test_size=0.30, random_state=42)
                    
                    # Store X_test and y_test in the IoT_Device class for final model testing
                    self.X_test = X_test
                    self.y_test = y_test
                    
                    # Do a secondary split - for training model with 30% validation dataset
                    X_train_tt, X_val_tt, y_train_tt, y_val_tt = train_test_split(X_train, y_train, test_size=0.30, random_state=42)
                    
                    #Standardize data
                    ss = StandardScaler()
                                
                    # Apply transform to both the training set and the test set.
                    X_train_tt_ss = ss.fit_transform(X_train_tt)
                    X_val_tt_ss  = ss.transform(X_val_tt)

                    if model_name == "LogisticRegression":
                        '''
                        We will do the following here.
                        1) LogisticRegression on the training and validation set
                        2) Creeate Confution Matrix with the training and test results
                        '''
                        # Istantiate Logistic Regression classifier
                        lg = LogisticRegression(random_state=42)
                
                        # Fit and Predict Model
                        self.lg_train_cm, self.lg_val_cm, self.lg_train_prediction, self.lg_val_prediction = \
                            self.iot_Fit_Predict_Report(lg, model_name, X_train_tt_ss, X_val_tt_ss, y_train_tt, y_val_tt)
                        self.lg_model =lg
                        
                        # Finally, print confusion maxtrix of test data
                        X_test_ss  = ss.transform(X_test)
                        y_hat_test = lg.predict(X_test_ss)
                        title_test = "[" + self.device_name + "] [Final Test Data] " + model_name
                        self.lg_test_cm, train_cm = self.iot_confusion_matrix( False, y_test, y_hat_test, title_test)
                        self.lg_test_prediction = y_hat_test       
                        
                        self.lg_model_score = self.iot_model_score(self.lg_test_cm, "LR")
                                                   

                    elif model_name ==  "KNeighborsClassifier":
                        '''
                        We will do the following here.
                        1) KNeighborsClassifier on the training and validation set
                        2) Creeate Confution Matrix with the training and test results
                        '''
                        knn = KNeighborsClassifier(5, n_jobs=-1)
                
                        # Fit and Predict Model
                        self.knn_train_cm, self.knn_val_cm, self.knn_train_prediction, self.knn_val_prediction = \
                            self.iot_Fit_Predict_Report(knn, model_name, X_train_tt_ss, X_val_tt_ss, y_train_tt, y_val_tt)
                        self.knn_model =knn
                        
                        # Finally, print confusion maxtrix of test data
                        X_test_ss  = ss.transform(X_test)
                        y_hat_test = knn.predict(X_test_ss)
                        title_test = "[" + self.device_name + "] [Final Test Data] " + model_name
                        self.knn_test_cm, train_cm = self.iot_confusion_matrix( False, y_test, y_hat_test, title_test)
                        self.knn_test_prediction = y_hat_test
                        
                        self.knn_model_score = self.iot_model_score(self.knn_test_cm, "KNN")
                
                    elif model_name == "DecisionTreeClassifier":
                        '''
                        We will do the following here.
                        1) DecisionTreeClassifier on the training and validation set
                        2) Creeate Confution Matrix with the training and test results
                        '''
                        dt = DecisionTreeClassifier(random_state = 42)
                        
                        # Fit and Predict Model
                        self.dt_train_cm, self.dt_val_cm, self.dt_train_prediction, self.dt_val_prediction = \
                            self.iot_Fit_Predict_Report(dt, model_name, X_train_tt_ss, X_val_tt_ss, y_train_tt, y_val_tt)
                        self.dt_model = dt
                        
                        # Finally, print confusion maxtrix of test data
                        X_test_ss  = ss.transform(X_test)
                        y_hat_test = dt.predict(X_test_ss)
                        title_test = "[" + self.device_name + "] [Final Test Data] " + model_name
                        self.dt_test_cm, train_cm = self.iot_confusion_matrix( False, y_test, y_hat_test, title_test)
                        self.dt_test_prediction = y_hat_test    
                        self.dt_model_score = self.iot_model_score(self.dt_test_cm, "DT")

                    elif model_name == "RandomForestClassifer":  
                        '''
                        We will do the following here.
                        1) RandomForest on the training and validation set
                        2) Create Confution Matrix with the training and test results
                        '''
                        # Instantiate XGBClassifier
                        rfc = RandomForestClassifier(random_state=42)
                
                        # Fit and Predict Model
                        self.rfc_train_cm, self.rfc_val_cm, self.rfc_train_prediction, self.rfc_val_prediction = \
                            self.iot_Fit_Predict_Report(rfc, model_name, X_train_tt_ss, X_val_tt_ss, y_train_tt, y_val_tt)
                        self.rfc_model = rfc   
                        
                        # Finally, print confusion maxtrix of test data
                        X_test_ss  = ss.transform(X_test)
                        y_hat_test = rfc.predict(X_test_ss)
                        title_test = "[" + self.device_name + "] [Final Test Data] " + model_name
                        self.rfc_test_cm, train_cm = self.iot_confusion_matrix( False, y_test, y_hat_test, title_test)
                        self.rfc_test_prediction = y_hat_test
                        self.rfc_model_score = self.iot_model_score(self.rfc_test_cm, "RFC")
                        
#                         # Do hyperparameter tuning
#                         self.rfc_hyper_recall = self.iot_randomforest_hyperparameter_tuning("recall")
#                         self.rfc_hyper_accuracy =self.iot_randomforest_hyperparameter_tuning("accuracy")

                    elif model_name == "XGBClassifier":
                        '''
                        We will do the following here.
                        1) RandomForest on the training and validation set
                        2) Creeate Confution Matrix with the training and test results
                        '''
                        # Instantiate XGBClassifier
                        xgb = XGBClassifier(random_state=42)
                
                        # Fit and Predict Model
                        self.xgb_train_cm, self.xgb_val_cm, self.xgb_train_prediction, self.xgb_val_prediction = \
                            self.iot_Fit_Predict_Report(xgb, model_name, X_train_tt_ss, X_val_tt_ss, y_train_tt, y_val_tt)
                        self.xgb_model = xgb 
                        
                        #Finally, print confusion maxtrix of test data
                        X_test_ss  = ss.transform(X_test)
                        y_hat_test = xgb.predict(X_test_ss)
                        title_test = "[" + self.device_name + "] [Final Test Data] " + model_name
                        self.xgb_test_cm, train_cm = self.iot_confusion_matrix( False, y_test, y_hat_test, title_test)
                        self.xgb_test_prediction = y_hat_test
                        self.xgb_model_score = self.iot_model_score(self.xgb_test_cm, "XGB")
                        
#                         # Do hyperparameter tuning
#                         self.xgb_hyper_recall = self.iot_xgboost_hyperparameter_tuning("recall")
#                         self.xgb_hyper_accuracy = self.iot_xgboost_hyperparameter_tuning("accuracy")
                        

                    else:
                        Print("Incorrect model. Refer to iot.iot_Model_")
  


    def iot_compare_recall_accuracy(self, test): 

        training_recall_benign = []
        training_recall_mirai = []
        training_recall_gafgyt = []
        testing_recall_benign = []
        testing_recall_mirai = []
        testing_recall_gafgyt = []      
        testing_recall_macro_average = []
        training_recall_macro_average = []
        training_accuracy = []
        testing_accuracy =[]


        for i in range(70, 100):
            X_train, X_test, y_train, y_test = train_test_split(self.X, self.y, test_size=i/100.0)
            
            if test == "LogisticRegression":
                model = LogisticRegression(fit_intercept=False, C=1e25, solver='liblinear')
            elif test == "KNeighborsClassifier":
                model = KNeighborsClassifier(5, n_jobs=-1)
                
            model = model.fit(X_train, y_train)
            
            y_hat_test = model.predict(X_test)
            y_hat_train = model.predict(X_train)
            
            cm_test = confusion_matrix(y_test, y_hat_test)
            cm_train = confusion_matrix(y_train, y_hat_train)

            for i in [0,1,2]:
                training_recall_benign.append(self.recall(i, cm_train))
                testing_recall_benign.append(self.recall(i, cm_test))  
                training_recall_mirai.append(self.recall(i, cm_train))
                testing_recall_mirai.append(self.recall(i, cm_test))                                  
                training_recall_gafgyt.append(self.recall(i, cm_train))
                testing_recall_gafgyt.append(self.recall(i, cm_test))  
            testing_recall_macro_average.append(self.recall_macro_average(cm_test))
            training_recall_macro_average.append(self.recall_macro_average(cm_train))            

            training_accuracy.append(self.accuracy(cm_train))
            testing_accuracy.append(self.accuracy(cm_train))

#         Train and test recall_benign
#        plt.plot(list(range(0,90)), training_recall_benign, label='training_recall_benign')
        plt.plot(list(range(0,90)), training_recall_mirai, label='training_recall_mirai')
        plt.plot(list(range(0,90)), testing_recall_mirai, label='testing_recall_mirai')
        plt.plot(list(range(0,90)), testing_recall_gafgyt, label='testing_recall_gafgyt')   
        plt.plot(list(range(0,30)), testing_accuracy, label='testing_accuracy')   
        
        plt.legend()
        plt.show()

