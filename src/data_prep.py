'''
    data_prep.py contains:
        (1) Class IoT_Device loads data from the datasets
        (2) Runs prediction models:
            a) LogisticRegression
'''
import os
import pandas as pd
import numpy as np

from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV
from sklearn.impute import SimpleImputer
from sklearn.utils import resample
from sklearn.decomposition import PCA
from sklearn.neighbors import KNeighborsClassifier
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.metrics import confusion_matrix, classification_report
from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor
from sklearn.pipeline import Pipeline
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import plot_confusion_matrix
from sklearn import metrics

import matplotlib.pyplot as plt
import seaborn as sns

import itertools

def list_iot_devices():
    # List of all IoT devices for which data was collcted
    device_list = {"Door_Bell": {"Damini_Doorbell":1, "Ennino_Doorbell":2},
               "Thermostats": {"Ecobee_Thermostat":1},
               "Baby_Monitor": {"Philips_B120N10_Baby_Monitor":1},
               "Security_Camera": {"Provision_PT_737E_Security_Camera":1,
                                   "Provision_PT_838_Security_Camera":2,
                                   "SimpleHome_XCS7_1002_WHT_Security_Camera":3,
                                   "SimpleHome_XCS7_1003_WHT_Security_Camera":4}}
   
    print("{:<17} {:<41} {:<60}".format('_______________','________________________________________','______'))
    print("{:<17} {:<41} {:<60}".format('Decice Category','Device','Number'))
    print("{:<17} {:<41} {:<60}".format('_______________','________________________________________','______'))
    
    for device,iots in device_list.items():
        for iot,val in device_list[device].items():
            print("{:<17} {:<41} {:<60}".format(device, iot, val)) 

def make_confusion_matrix(cf,
              group_names=None,
              categories='auto',
              count=True,
              percent=True,
              cbar=True,
              xyticks=True,
              xyplotlabels=True,
              sum_stats=True,
              figsize=None,
              cmap='coolwarm',
              title=None):
    '''
    This function will make a pretty plot of an sklearn Confusion Matrix cm using a Seaborn heatmap visualization.
    Arguments
    ---------
    cf:            confusion matrix to be passed in
    group_names:   List of strings that represent the labels row by row to be shown in each square.
    categories:    List of strings containing the categories to be displayed on the x,y axis. Default is 'auto'
    count:         If True, show the raw number in the confusion matrix. Default is True.
    normalize:     If True, show the proportions for each category. Default is True.
    cbar:          If True, show the color bar. The cbar values are based off the values in the confusion matrix.
                   Default is True.
    xyticks:       If True, show x and y ticks. Default is True.
    xyplotlabels:  If True, show 'True Label' and 'Predicted Label' on the figure. Default is True.
    sum_stats:     If True, display summary statistics below the figure. Default is True.
    figsize:       Tuple representing the figure size. Default will be the matplotlib rcParams value.
    cmap:          Colormap of the values displayed from matplotlib.pyplot.cm. Default is 'Blues'
                   See http://matplotlib.org/examples/color/colormaps_reference.html
                   
    title:         Title for the heatmap. Default is None.
    '''


    # CODE TO GENERATE TEXT INSIDE EACH SQUARE
    blanks = ['' for i in range(cf.size)]

    if group_names and len(group_names)==cf.size:
        group_labels = ["{}\n".format(value) for value in group_names]
    else:
        group_labels = blanks

    if count:
        group_counts = ["{0:0.0f}\n".format(value) for value in cf.flatten()]
    else:
        group_counts = blanks

    if percent:
        group_percentages = ["{0:.2%}".format(value) for value in cf.flatten()/np.sum(cf)]
    else:
        group_percentages = blanks

    box_labels = [f"{v1}{v2}{v3}".strip() for v1, v2, v3 in zip(group_labels,group_counts,group_percentages)]
    box_labels = np.asarray(box_labels).reshape(cf.shape[0],cf.shape[1])


    # Generate Summary Stats
    if sum_stats:
        #Accuracy is sum of diagonal divided by total observations
        accuracy  = np.trace(cf) / float(np.sum(cf))

        #if it is a binary confusion matrix, show some more stats
        if len(cf)==2:
            #Metrics for Binary Confusion Matrices
            precision = cf[1,1] / sum(cf[:,1])
            recall    = cf[1,1] / sum(cf[1,:])
            f1_score  = 2*precision*recall / (precision + recall)
            stats_text = "\n\nAccuracy={:0.3f}\nPrecision={:0.3f}\nRecall={:0.3f}\nF1 Score={:0.3f}".format(
                accuracy,precision,recall,f1_score)
        else:
            stats_text = "\n\nAccuracy={:0.3f}".format(accuracy)
    else:
        stats_text = ""


    # SET FIGURE PARAMETERS ACCORDING TO OTHER ARGUMENTS
    if figsize==None:
        #Get default figure size if not set
        figsize = plt.rcParams.get('figure.figsize')

    if xyticks==False:
        #Do not show categories if xyticks is False
        categories=False


    # MAKE THE HEATMAP VISUALIZATION
    plt.figure(figsize=figsize)
    sns.heatmap(cf,annot=box_labels,fmt="",cmap=cmap,cbar=cbar,xticklabels=categories,yticklabels=categories)
        
    if xyplotlabels:
        plt.ylabel('True label')
        plt.xlabel('Predicted label' + stats_text)
    else:
        plt.xlabel(stats_text)
    
    if title:
        plt.title(title)

class IoT_Device:
    '''


    '''
    def __init__(self,device):  
        self.device = device
        self.iot_dataframe()
        self.threat_class_dict = {"Class": {"Benign":0, "Mirai_ACK":1, "Mirai_SCAN":2, "Mirai_SYN":3, "Mirai_UDP":4, "Mirai_UDPPLAIN":5,
                            "Gafgyt_COMBO":6, "Gafgyt_JUNK":7, "Gafgyt_SCAN":8, "Gafgyt_TCP":9, "Gafgyt_UDP":10}}
        
    def create_df (self, filename):
        '''
            Method: Create_df
            Input: filename, device
            Action: Read filename and return datafram
        '''
        df = {}
        if os.path.exists(filename):
            df = pd.read_csv(filename)
        else:
            print("{} datafile does not exist for {}".format(filename, self.device))
        return df  
    
    def iot_dataframe(self):
        '''

        '''    
        # First path to benign, mirai, gafgyt data files
        print(f"Preparing data for ***** {self.device} *****")
        benign_data = "../../data/"+ self.device +"/benign_traffic.csv"
        mirai_path = "../../data/"+ self.device +"/mirai_attacks/"
        gafgyt_path = "../../data/"+ self.device +"/gafgyt_attacks/"
    
        #Benign dataframe
        df_benign = self.create_df(benign_data)
        df_benign['Class'] = 0
        '''
            For the device, create mirai dataframes for ack, scan, syn, udp, udpplain attack files
        '''
        # 1. ack.csv
        fn = mirai_path+"ack.csv"
        df_mirai_ack = self.create_df(benign_data)
        df_mirai_ack['Class'] = 1
        
        #2 scan.csv    
        fn = mirai_path+"scan.csv"
        df_mirai_scan = self.create_df(fn)
        df_mirai_scan['Class'] = 1
        
        #3 syn.csv    
        fn = mirai_path+"syn.csv"        
        df_mirai_syn = self.create_df(fn)       
        df_mirai_syn['Class'] = 1
        
        #4 udp.csv    
        fn = mirai_path+"udp.csv"
        df_mirai_udp = self.create_df(fn) 
        df_mirai_udp['Class'] = 1
    
        #5 udpplain.csv    
        fn = mirai_path+"udpplain.csv"
        df_mirai_udpplain = self.create_df(fn) 
        df_mirai_udpplain['Class'] = 1
        
        '''
            For the device, create gafgyt attack dataframes for ack, scan, syn, udp, udpplain attack data files
        '''
        # 1. combo.csv
        fn = gafgyt_path+"combo.csv"
        df_gafgyt_combo = self.create_df(fn) 
        df_gafgyt_combo['Class'] = 2
        
        #2 junk.csv    
        fn = gafgyt_path+"junk.csv"
        df_gafgyt_junk = self.create_df(fn) 
        df_gafgyt_junk['Class'] = 2
        
        #3 scan.csv    
        fn = gafgyt_path+"scan.csv"
        df_gafgyt_scan = self.create_df(fn) 
        df_gafgyt_scan['Class'] = 2

        #4 tcp.csv    
        fn = gafgyt_path+"tcp.csv"
        df_gafgyt_tcp = self.create_df(fn) 
        df_gafgyt_tcp['Class'] = 2
    
        #5 udp.csv    
        fn = gafgyt_path+"udp.csv"
        df_gafgyt_udp = self.create_df(fn) 
        df_gafgyt_udp['Class'] = 2
        
        lst_df = [df_benign, df_mirai_ack, df_mirai_scan, df_mirai_syn, df_mirai_udp, df_mirai_udpplain,
                  df_gafgyt_combo, df_gafgyt_junk, df_gafgyt_scan, df_gafgyt_tcp, df_gafgyt_udp]
        
        mirai_df = [df_mirai_ack, df_mirai_scan, df_mirai_syn, df_mirai_udp, df_mirai_udpplain]
        gafgyt_df = [df_gafgyt_combo, df_gafgyt_junk, df_gafgyt_scan, df_gafgyt_tcp, df_gafgyt_udp]
        
        mirai_df = pd.concat(mirai_df, ignore_index=True)
        gafgyt_df = pd.concat(gafgyt_df, ignore_index=True)    
        
        # Downsample mirai_df and gafgyt_df to be similar to df_benign
        mirai_df = resample(mirai_df, 
                             replace=False, 
                             n_samples=len(df_benign),
                             random_state = 42)
        gafgyt_df = resample(gafgyt_df, 
                             replace=False, 
                             n_samples=len(df_benign),
                             random_state = 42)
           
        
        #Create the massive dataframe with everything for the IoT device
        data = pd.concat([df_benign, mirai_df, gafgyt_df], ignore_index=True)  
        
        val = data['Class'].value_counts()

        print( "\nMulti-Classification target category:\n", val)
        print( "\n\nMinimum number of records: {}  Maximium number of records: {}".format(val.min(), val.max()))     
                
        # Save target(y) and predictors(X) as class variables
        self.X = data.drop("Class", axis=1)
        self.y = data["Class"]
        
        val = self.y.value_counts()
        print( "\n\nBinary category: {} number of records\n", val)
        print( "\nMinimum number of records: {}  Maximium number of records: {}".format(val.min(), val.max()))
        
        # EDA processing goes here      
#         # Let's store training and testing data in the class itself for use when we test several models
#         self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(X, y, random_state = 42, test_size = 0.30)

    def iot_convert_target_values(self, binary):
        if binary == True:
            threat_class = {"Benign":0, "Mirai_ACK":1, "Mirai_SCAN":1, "Mirai_SYN":1, "Mirai_UDP":1, "Mirai_UDPPLAIN":1,
                            "Gafgyt_COMBO":2, "Gafgyt_JUNK":2, "Gafgyt_SCAN":2, "Gafgyt_TCP":2, "Gafgyt_UDP":2}
            self.y = self.y.replace(threat_class) 
        else:
            threat_class = {0:"Benign", 1:"Mirai_ACK", 2:"Mirai_SCAN", 3:"Mirai_SYN", 4:"Mirai_UDP", 5:"Mirai_UDPPLAIN",
            6:"Gafgyt_COMBO", 7:"Gafgyt_JUNK", 8:"Gafgyt_SCAN", 9:"Gafgyt_TCP", 10:"Gafgyt_UDP"}
            self.y = self.y.replace(threat_class)        
        
        
    def iot_Model(self, model): 
        '''
            IoT_FSM method will perform a first simple model with LogisticRegression with all default parameters, except max_iter=1000 otherwise cpu is going crazy
            
            Method: IoT_FSM
            Input: None
            Action: 1) Change target to binary, for FSM only.
                    2) Instantiate LogisticRegression classifier
                    3) Fit model
                    4) Run cross_val_score
        '''   
        # Train test split - to hold out test data for prediction
        X_train, X_test, y_train, y_test = train_test_split(self.X, self.y, test_size=0.30, random_state=42)
        
        #Standardize data
        ss = StandardScaler()
                
        # Apply transform to both the training set and the test set.
        X_train_ss = ss.fit_transform(X_train)
        X_test_ss  = ss.fit_transform(X_test)
        if model == "LogisticRegression":
            # Istantiate Logistic Regression classifier
            lg_fsm = LogisticRegression()
            lg_fsm.fit(X_train_ss, y_train)        
            y_hat = lg_fsm.predict(X_test_ss) 
            title = "FSM: LigisticRegression-"+self.device
        
        elif model ==  "KNeighborsClassifier":
            knn = KNeighborsClassifier(3)
            knn.fit(X_train_ss, y_train)
            y_hat = knn.predict(X_test_ss)
            title = "KNeighborsClassifier"+self.device
            
        elif model == "DecisionTreeClassifier":
            dt = DecisionTreeClassifier(random_state = 42)
            dt.fit(X_train_ss, y_train)
            y_hat = dt.predict(X_test_ss)
            title = "DecisionTreeClassifer"+self.device 
            

            
        cm = confusion_matrix(y_test, y_hat)     
        
        # how did our model perform?
        make_confusion_matrix(cm, figsize=(8,6), categories=["Benign", "Mirai", "Gafgyt"], cbar=False, title="FSM: LigisticRegression-"+self.device, sum_stats=True)



        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
#______ SAVE temporarily
#     def iot_dataframe(self):
#         '''

#         '''    
#         # First path to benign, mirai, gafgyt data files
#         print(f"Preparing data for ***** {self.device} *****")
#         benign_data = "../../data/"+ self.device +"/benign_traffic.csv"
#         mirai_path = "../../data/"+ self.device +"/mirai_attacks/"
#         gafgyt_path = "../../data/"+ self.device +"/gafgyt_attacks/"
    
#         #Benign dataframe
#         df_benign = self.create_df(benign_data)
#         df_benign['Class'] = "Benign"

#         '''
#             For the device, create mirai dataframes for ack, scan, syn, udp, udpplain attack files
#         '''
#         # 1. ack.csv
#         fn = mirai_path+"ack.csv"
#         df_mirai_ack = self.create_df(benign_data)
#         df_mirai_ack['Class'] = "Mirai_ACK"
        
#         #2 scan.csv    
#         fn = mirai_path+"scan.csv"
#         df_mirai_scan = self.create_df(fn)
#         df_mirai_scan['Class'] = "Mirai_SCAN"  
        
#         #3 syn.csv    
#         fn = mirai_path+"syn.csv"        
#         df_mirai_syn = self.create_df(fn)       
#         df_mirai_syn['Class'] = "Mirai_SYN"
        
#         #4 udp.csv    
#         fn = mirai_path+"udp.csv"
#         df_mirai_udp = self.create_df(fn) 
#         df_mirai_udp['Class'] = "Mirai_UDP"
    
#         #5 udpplain.csv    
#         fn = mirai_path+"udpplain.csv"
#         df_mirai_udpplain = self.create_df(fn) 
#         df_mirai_udpplain['Class'] = "Mirai_UDPPLAIN"
        
#         '''
#             For the device, create gafgyt attack dataframes for ack, scan, syn, udp, udpplain attack data files
#         '''
#         # 1. combo.csv
#         fn = gafgyt_path+"combo.csv"
#         df_gafgyt_combo = self.create_df(fn) 
#         df_gafgyt_combo['Class'] = "Gafgyt_COMBO"
        
#         #2 junk.csv    
#         fn = gafgyt_path+"junk.csv"
#         df_gafgyt_junk = self.create_df(fn) 
#         df_gafgyt_junk['Class'] = "Gafgyt_JUNK"
        
#         #3 scan.csv    
#         fn = gafgyt_path+"scan.csv"
#         df_gafgyt_scan = self.create_df(fn) 
#         df_gafgyt_scan['Class'] = "Gafgyt_SCAN"

#         #4 tcp.csv    
#         fn = gafgyt_path+"tcp.csv"
#         df_gafgyt_tcp = self.create_df(fn) 
#         df_gafgyt_tcp['Class'] = "Gafgyt_TCP"
    
#         #5 udp.csv    
#         fn = gafgyt_path+"udp.csv"
#         df_gafgyt_udp = self.create_df(fn) 
#         df_gafgyt_udp['Class'] = "Gafgyt_UDP"
        
#         lst_df = [df_benign, df_mirai_ack,df_mirai_syn, df_mirai_udp, df_mirai_udpplain,
#                   df_gafgyt_combo, df_gafgyt_junk, df_gafgyt_scan, df_gafgyt_tcp, df_gafgyt_udp]
        
#         len_lst = []
#         min_records = min([len_lst.append(len(df)) for df in lst_df])
#         print(f"sampling {min_rcords} in every datafile")                  

            
        
#         #Create the massive dataframe with everything for the IoT device
#         data = pd.concat(lst_df, ignore_index=False)  
        
#         val = data['Class'].value_counts()

#         print( "\nMulti-Classification target category:\n", val)
#         print( "\n\nMinimum number of records: {}  Maximium number of records: {}".format(val.min(), val.max()))     
                
#         # Save target(y) and predictors(X) as class variables
#         self.X = data.drop("Class", axis=1)
#         self.y = data["Class"]
        
#         # Replace Classification to Numberic 
#         self.iot_convert_target_values(True)
        
#         val = self.y.value_counts()
#         print( "\n\nBinary category: {} number of records\n", val)
#         print( "\nMinimum number of records: {}  Maximium number of records: {}".format(val.min(), val.max()))
        
#         # EDA processing goes here      
# #         # Let's store training and testing data in the class itself for use when we test several models
# #         self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(X, y, random_state = 42, test_size = 0.30)