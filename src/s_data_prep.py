'''
    data_prep.py contains:
        (1) Class IoT_Device loads data from the datasets
        (2) Runs prediction models:
            a) LogisticRegression
'''
import os
import pandas as pd
import numpy as np
from sklearn.dummy import DummyClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV
from sklearn.impute import SimpleImputer
from sklearn.utils import resample
from sklearn.decomposition import PCA
from sklearn.neighbors import KNeighborsClassifier
from xgboost import XGBClassifier
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.metrics import confusion_matrix, classification_report
from yellowbrick.classifier import ClassificationReport # conda install -c districtdatalabs yellowbrick
from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor
from sklearn.pipeline import Pipeline
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import plot_confusion_matrix, roc_curve, auc
from sklearn import metrics
#import lightgbm 
from lightgbm import *

from xgboost import XGBClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import BaggingClassifier, RandomForestClassifier
from sklearn.naive_bayes import GaussianNB
import lightgbm as lgb

import matplotlib.pyplot as plt
import seaborn as sns
sns.set(font_scale=1.5)

import itertools

def list_iot_devices():
    # List of all IoT devices for which data was collcted
    device_list = {"Door_Bell": {"Damini_Doorbell":1, "Ennino_Doorbell":2},
               "Thermostats": {"Ecobee_Thermostat":1},
               "Baby_Monitor": {"Philips_B120N10_Baby_Monitor":1},
               "Security_Camera": {"Provision_PT_737E_Security_Camera":1,
                                   "Provision_PT_838_Security_Camera":2,
                                   "SimpleHome_XCS7_1002_WHT_Security_Camera":3,
                                   "SimpleHome_XCS7_1003_WHT_Security_Camera":4}}
   
    print("{:<17} {:<41} {:<60}".format('_______________','________________________________________','______'))
    print("{:<17} {:<41} {:<60}".format('Decice Category','Device','Number'))
    print("{:<17} {:<41} {:<60}".format('_______________','________________________________________','______'))
    
    for device,iots in device_list.items():
        for iot,val in device_list[device].items():
            print("{:<17} {:<41} {:<60}".format(device, iot, val)) 
    return device_list

def make_confusion_matrix(cf,
              group_names=None,
              categories='auto',
              count=True,
              percent=True,
              cbar=True,
              xyticks=True,
              xyplotlabels=True,
              sum_stats=True,
              figsize=None,
              cmap='coolwarm',
              title=None):
    '''
    This function will make a pretty plot of an sklearn Confusion Matrix cm using a Seaborn heatmap visualization.
    Arguments
    ---------
    cf:            confusion matrix to be passed in
    group_names:   List of strings that represent the labels row by row to be shown in each square.
    categories:    List of strings containing the categories to be displayed on the x,y axis. Default is 'auto'
    count:         If True, show the raw number in the confusion matrix. Default is True.
    normalize:     If True, show the proportions for each category. Default is True.
    cbar:          If True, show the color bar. The cbar values are based off the values in the confusion matrix.
                   Default is True.
    xyticks:       If True, show x and y ticks. Default is True.
    xyplotlabels:  If True, show 'True Label' and 'Predicted Label' on the figure. Default is True.
    sum_stats:     If True, display summary statistics below the figure. Default is True.
    figsize:       Tuple representing the figure size. Default will be the matplotlib rcParams value.
    cmap:          Colormap of the values displayed from matplotlib.pyplot.cm. Default is 'Blues'
                   See http://matplotlib.org/examples/color/colormaps_reference.html
                   
    title:         Title for the heatmap. Default is None.
    '''


    # CODE TO GENERATE TEXT INSIDE EACH SQUARE
    blanks = ['' for i in range(cf.size)]

    if group_names and len(group_names)==cf.size:
        group_labels = ["{}\n".format(value) for value in group_names]
    else:
        group_labels = blanks

    if count:
        group_counts = ["{0:0.0f}\n".format(value) for value in cf.flatten()]
    else:
        group_counts = blanks

    if percent:
        group_percentages = ["{0:.2%}".format(value) for value in cf.flatten()/np.sum(cf)]
    else:
        group_percentages = blanks

    box_labels = [f"{v1}{v2}{v3}".strip() for v1, v2, v3 in zip(group_labels,group_counts,group_percentages)]
    box_labels = np.asarray(box_labels).reshape(cf.shape[0],cf.shape[1])


    # Generate Summary Stats
    if sum_stats:
        #Accuracy is sum of diagonal divided by total observations
        accuracy  = np.trace(cf) / float(np.sum(cf))

        #if it is a binary confusion matrix, show some more stats
        if len(cf)==2:
            #Metrics for Binary Confusion Matrices
            precision = cf[1,1] / sum(cf[:,1])
            recall    = cf[1,1] / sum(cf[1,:])
            f1_score  = 2*precision*recall / (precision + recall)
            stats_text = "\n\nAccuracy={:0.3f}\nPrecision={:0.3f}\nRecall={:0.3f}\nF1 Score={:0.3f}".format(
                accuracy,precision,recall,f1_score)
        else:
            stats_text = "\n\nAccuracy={:0.3f}".format(accuracy)
    else:
        stats_text = ""


    # SET FIGURE PARAMETERS ACCORDING TO OTHER ARGUMENTS
    if figsize==None:
        #Get default figure size if not set
        figsize = plt.rcParams.get('figure.figsize')

    if xyticks==False:
        #Do not show categories if xyticks is False
        categories=False


    # MAKE THE HEATMAP VISUALIZATION
    fig = plt.figure(figsize=figsize)
    sns.heatmap(cf,annot=box_labels,fmt="",cmap=cmap,cbar=cbar,xticklabels=categories,yticklabels=categories)
        
    if xyplotlabels:
        plt.ylabel('True label')
        plt.xlabel('Predicted label' + stats_text)
    else:
        plt.xlabel(stats_text)
    
    if title:
        plt.title(title)
    fig.savefig("../../visualization/"+title+".png")
    plt.show()
    

class IoT_Device:
    '''


    '''
    def __init__(self,device):  
        self.device = device
        self.iot_dataframe()
        self.threat_class_dict = {"Class": {"Benign":0, "Mirai_ACK":1, "Mirai_SCAN":2, "Mirai_SYN":3, "Mirai_UDP":4, "Mirai_UDPPLAIN":5,
                            "Gafgyt_COMBO":6, "Gafgyt_JUNK":7, "Gafgyt_SCAN":8, "Gafgyt_TCP":9, "Gafgyt_UDP":10}}
        self.num_class = [0,1,2]
        self.str_class = ["Benign", "Mirai", "Gafgyt"]
        
    def create_df (self, filename):
        '''
            Method: Create_df
            Input: filename, device
            Action: Read filename and return datafram
        '''
        df = {}
        if os.path.exists(filename):
            df = pd.read_csv(filename)
        else:
            print("{} datafile does not exist for {}".format(filename, self.device))
        return df  
    
    def iot_dataframe(self):
        '''

        '''    
        # First path to benign, mirai, gafgyt data files
        print(f"Preparing data for ***** {self.device} *****")
        benign_data = "../../data/"+ self.device +"/benign_traffic.csv"
        mirai_path = "../../data/"+ self.device +"/mirai_attacks/"
        gafgyt_path = "../../data/"+ self.device +"/gafgyt_attacks/"
    
        #Benign dataframe
        df_benign = self.create_df(benign_data)
        df_benign['Class'] = 0
        '''
            For the device, create mirai dataframes for ack, scan, syn, udp, udpplain attack files
        '''
        # 1. ack.csv
        fn = mirai_path+"ack.csv"
        df_mirai_ack = self.create_df(benign_data)
        df_mirai_ack['Class'] = 1
        
        #2 scan.csv    
        fn = mirai_path+"scan.csv"
        df_mirai_scan = self.create_df(fn)
        df_mirai_scan['Class'] = 1
        
        #3 syn.csv    
        fn = mirai_path+"syn.csv"        
        df_mirai_syn = self.create_df(fn)       
        df_mirai_syn['Class'] = 1
        
        #4 udp.csv    
        fn = mirai_path+"udp.csv"
        df_mirai_udp = self.create_df(fn) 
        df_mirai_udp['Class'] = 1
    
        #5 udpplain.csv    
        fn = mirai_path+"udpplain.csv"
        df_mirai_udpplain = self.create_df(fn) 
        df_mirai_udpplain['Class'] = 1
        
        '''
            For the device, create gafgyt attack dataframes for ack, scan, syn, udp, udpplain attack data files
        '''
        # 1. combo.csv
        fn = gafgyt_path+"combo.csv"
        df_gafgyt_combo = self.create_df(fn) 
        df_gafgyt_combo['Class'] = 2
        
        #2 junk.csv    
        fn = gafgyt_path+"junk.csv"
        df_gafgyt_junk = self.create_df(fn) 
        df_gafgyt_junk['Class'] = 2
        
        #3 scan.csv    
        fn = gafgyt_path+"scan.csv"
        df_gafgyt_scan = self.create_df(fn) 
        df_gafgyt_scan['Class'] = 2

        #4 tcp.csv    
        fn = gafgyt_path+"tcp.csv"
        df_gafgyt_tcp = self.create_df(fn) 
        df_gafgyt_tcp['Class'] = 2
    
        #5 udp.csv    
        fn = gafgyt_path+"udp.csv"
        df_gafgyt_udp = self.create_df(fn) 
        df_gafgyt_udp['Class'] = 2
        
        lst_df = [df_benign, df_mirai_ack, df_mirai_scan, df_mirai_syn, df_mirai_udp, df_mirai_udpplain,
                  df_gafgyt_combo, df_gafgyt_junk, df_gafgyt_scan, df_gafgyt_tcp, df_gafgyt_udp]
        
        mirai_df = [df_mirai_ack, df_mirai_scan, df_mirai_syn, df_mirai_udp, df_mirai_udpplain]
        gafgyt_df = [df_gafgyt_combo, df_gafgyt_junk, df_gafgyt_scan, df_gafgyt_tcp, df_gafgyt_udp]
        
        mirai_df = pd.concat(mirai_df, ignore_index=True)
        gafgyt_df = pd.concat(gafgyt_df, ignore_index=True)    
        
#         # Downsample mirai_df and gafgyt_df to be similar to df_benign
#         mirai_df = resample(mirai_df, 
#                              replace=False, 
#                              n_samples=len(df_benign),
#                              random_state = 42)
#         gafgyt_df = resample(gafgyt_df, 
#                              replace=False, 
#                              n_samples=len(df_benign),
#                              random_state = 42)
           
        
        #Create the massive dataframe with everything for the IoT device
        data = pd.concat([df_benign, mirai_df, gafgyt_df], ignore_index=True)  
        
        val = data['Class'].value_counts()

        print( "\nMulti-Classification target category:\n", val)
        print( "\n\nMinimum number of records: {}  Maximium number of records: {}".format(val.min(), val.max()))     
                
        # Save target(y) and predictors(X) as class variables
        self.X = data.drop("Class", axis=1)
        self.y = data["Class"]
        
        val = self.y.value_counts()
        print( "\n\nBinary category: {} number of records\n", val)
        print( "\nMinimum number of records: {}  Maximium number of records: {}".format(val.min(), val.max()))                

    def iot_confusion_matrix(self, print_train, y_test, y_hat_test, title_test, y_train=None, y_hat_train=None, title_train=None):
        '''
            This method will print confustion matrix for both train and test sets
        '''
        cm_train = cm_test = None
        # Run confustion_matric with the predicted value and the test set
        if print_train == True:
            cm_train = confusion_matrix(y_train, y_hat_train) 
            make_confusion_matrix(cm_train, figsize=(8,6), categories=["Benign", "Mirai", "Gafgyt"], cbar=False, title=title_train, sum_stats=True)

        # Run confustion_matric with the predicted value and the test set
        cm_test = confusion_matrix(y_test, y_hat_test)
        make_confusion_matrix(cm_test, figsize=(8,6), categories=["Benign", "Mirai", "Gafgyt"], cbar=False, title=title_test, sum_stats=True)
        return cm_test, cm_train
    
#     def iot_classification_report(self, model, X_train, X_test, y_train, y_test):

#         # Specify the target classes
#         classes = self.str_class

#         visualizer = ClassificationReport(model, classes=classes, support=True)
#         visualizer.fit(X_train, y_train)        # Fit the visualizer and the model
#         visualizer.score(X_test, y_test)        # Evaluate the model on the test data
#         visualizer.show()                       # Finalize and show the figure
    def iot_roc_curve(self, fpr, tpr, title):
        # Seaborn's beautiful styling
        sns.set_style('darkgrid', {'axes.facecolor': '0.9'})

        print('AUC: {}'.format(auc(fpr, tpr)))
        plt.figure(figsize=(10, 8))
        lw = 2
        plt.plot(fpr, tpr, color='darkorange',
                 lw=lw, label='ROC curve')
        plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')
        plt.xlim([0.0, 1.0])
        plt.ylim([0.0, 1.05])
        plt.yticks([i/20.0 for i in range(21)])
        plt.xticks([i/20.0 for i in range(21)])
        plt.xlabel('False Positive Rate')
        plt.ylabel('True Positive Rate')
        plt.title(title)
        plt.legend(loc='lower right')
        plt.show()
      
    def iot_Fit_Predict_Report(self, model, model_name,  X_train_ss, X_test_ss, y_train, y_test):
        # Fit Model
        model.fit(X_train_ss, y_train)
        
        # Predict and Report
        y_hat_train = model.predict(X_train_ss)
        y_hat_test = model.predict(X_test_ss)

        # print classification report to out put recall, precision, accuacy and F1 scores
        print(classification_report(y_test, y_hat_test))

        # print confustion_matric with the predicted values for test and train data
        title_test = "[" + self.device + "] [Test Data] " + model_name
        title_train ="[" + self.device + "] [Train Data] " + model_name

        # Store the model and results as a class variable
        test_cm, train_cm = self.iot_confusion_matrix( True, y_test, y_hat_test, title_test, y_train, y_hat_train, title_train )
        
        # Predict on training and test sets
        train_prediction  = model.predict(X_train_ss)
        test_prediction  = model.predict(X_test_ss)  
        
        return  test_cm, train_cm, test_prediction, train_prediction
        
    def iot_Model(self, model_name): 
        '''
            IoT_FSM method will perform a first simple model with LogisticRegression with all default parameters, except max_iter=1000 otherwise cpu is going crazy
            
            Method: IoT_FSM
            Input: "FSM", "LogisticRegression", "KNeighborsClassifier", "DecisionTreeClassifier", "RandomForestClassifer"
            Action: 1) Change target to binary, for FSM only.
                    2) Instantiate LogisticRegression classifier
                    3) Fit model
                    4) Run cross_val_score
        '''   
        if model_name == "DummyClassifier":
            dummy_model = DummyClassifier(strategy="most_frequent")
            dummy_model.fit(self.X, self.y)
            y_hat = dummy_model.predict(self.X)
            
            # print classification report to out put recall, precision, accuacy and F1 scores
            print(classification_report(self.y, y_hat))
                    
            self.dummy_model_cross_val_score = cross_val_score(dummy_model, self.X, self.y, cv=5)
            print(f"\n [{self.device}] Dummy Model: Raw Input Data--cross_val_score-", self.dummy_model_cross_val_score)
            title_test = "[" + self.device + "] [Test Data] "+ model_name
            title_train=""
            
            self.dummy_test_cm, self.dummy_train_cm = self.iot_confusion_matrix(False, self.y, y_hat, title_test, None, None, None)       

        elif model_name == "FSM":
            ss = StandardScaler()
            X_ss = ss.fit_transform(self.X)
            
            fsm = LogisticRegression()
            fsm.fit(X_ss,self.y)
            
            y_hat = fsm.predict(self.X)
            
            title_test = "[" + self.device + "] [Test Data] FSM-LogisticRegression"
            title_train =""
            
            # print classification report to out put recall, precision, accuacy and F1 scores
            print(classification_report(self.y, y_hat))            
            
            
            # Cross Validation Score
            self.fsm_cross_val_score = cross_val_score(fsm, self.X, self.y, cv=5)
            print(f"\n [{self.device}] FSM Model: Raw Input Data--cross_val_score-", self.fsm_cross_val_score)
            
            # Call iot_confusion_matrix  to print confustion matrix
            self.fsm_test_cm, self.fsm_train_cm = self.iot_confusion_matrix(False, self.y, y_hat, title_test, None, None, None)
            self.fsm_model = fsm
            
                        

        else:
                    # Train test split - to hold out test data for prediction
                    X_train, X_test, y_train, y_test = train_test_split(self.X, self.y, test_size=0.30, random_state=42)
                    
                    #Standardize data
                    ss = StandardScaler()
                                
                    # Apply transform to both the training set and the test set.
                    X_train_ss = ss.fit_transform(X_train)
                    X_test_ss  = ss.transform(X_test)

                    if model_name == "LogisticRegression":
                        # Istantiate Logistic Regression classifier
                        lg = LogisticRegression()
                        lg.fit(X_train_ss, y_train)        

                        y_hat_train = lg.predict(X_train_ss)
                        y_hat_test = lg.predict(X_test_ss) 
                        
                        # print classification report to out put recall, precision, accuacy and F1 scores
                        print(classification_report(y_test, y_hat_test))
                        
                        # print confustion_matric with the predicted values for test and train data
                        title_test = "[" + self.device + "] [Test Data] LogisticRegression"
                        title_train ="[" + self.device + "] [Train Data] LogisticRegression"
                        
                        # Store the model and results as a class variable
                        self.lg_test_cm, self.lg_train_cm = self.iot_confusion_matrix( True, y_test, y_hat_test, title_test, y_train, y_hat_train, title_train )
                        self.lg_model = lg
                        
#                         # Classification_Report
#                         self.iot_classification_report(self.lg_model, X_train, X_test, y_train, y_test)
                        self.X_test = X_test
                        self.X_train = X_train
                        self.X_test_ss = X_test_ss
                        self.X_train_ss = X_train_ss
                        self.y_train = y_train
                        self.y_test = y_test
#                         # ROC Curve
#                         title_roc = "["+self.device+"]"+ "LogisticRegression-Receiver operating characteristic (ROC) Curve"
#                         fpr, tpr, thresholds = roc_curve(y_test, lg.decision_function(X_test))
#                         print('AUC: {}'.format(auc(fpr, tpr)))
#                         iot_roc_curve(fpr, tpr, title_roc)
                     
                    elif model_name ==  "KNeighborsClassifier":
                        knn = KNeighborsClassifier(3, n_jobs=4)
                        knn.fit(X_train_ss, y_train)
                        
                        y_hat_train = knn.predict(X_train_ss)
                        y_hat_test = knn.predict(X_test_ss)
                        
                        title = "KNeighborsClassifier"+self.device
                        self.knn_model = knn
                        
                        # print classification report to out put recall, precision, accuacy and F1 scores
                        print(classification_report(y_test, y_hat_test))
                        
                        # print confustion_matric with the predicted values for test and train data
                        title_test = "[" + self.device + "] [Test Data] KNeisghborsClassifier"
                        title_train ="[" + self.device + "] [Train Data] KNeisghborsClassifier"
                        
                        
                        # Store the model and results as a class variable
                        self.knn_test_cm, self.knn_train_cm = self.iot_confusion_matrix( True, y_test, y_hat_test, title_test, y_train, y_hat_train, title_train )
                        self.knn_model = knn
                        
#                         # Classification_Report
#                         self.iot_classification_report(self.knn_model, X_train, X_test, y_train, y_test)

                    elif model_name == "DecisionTreeClassifier":
                        dt = DecisionTreeClassifier(random_state = 42)
                        dt.fit(X_train_ss, y_train)
                        
                        y_hat_train = dt.predict(X_train_ss)
                        y_hat_test = dt.predict(X_test_ss)
                        
                        # print classification report to out put recall, precision, accuacy and F1 scores
                        print(classification_report(y_test, y_hat_test))
                        
                        # print confustion_matric with the predicted values for test and train data
                        title_test = "[" + self.device + "] [Test Data] DecisionTreeClassifier"
                        title_train ="[" + self.device + "] [Train Data] DecisionTreeClassifier"
                        
                        # Store the model and results as a class variable
                        self.dt_test_cm, self.dt_train_cm = self.iot_confusion_matrix( True, y_test, y_hat_test, title_test, y_train, y_hat_train, title_train )
                        self.dt_model = dt
                        
#                         # Classification_Report
#                         self.iot_classification_report(self.dt_model, X_train, X_test, y_train, y_test)

                    elif model_name == "RandomForestClassifer":    
                        # Instantiate XGBClassifier
                        rfc = RandomForestClassifier()
                
                        # Fit and Predict Model
                        self.rfc_test_cm, self.rfc_train_cm, self.rfc_test_prediction, self.rfc_train_prediction = \
                            self.iot_Fit_Predict_Report(rfc, model_name, X_train_ss, X_test_ss, y_train, y_test)
                        self.xgb_model = rfc
#                         gs_param = { 'max_depth': [100],
#                                  'n_estimators': [1000]}
#                         gs = GridSearchCV(RandomForestClassifier()
#                         gs.fit(X_train_ss, y_train)
                        
#                         # print classification report to out put recall, precision, accuacy and F1 scores
#                         print(classification_report(y_test, y_hat_test))
                        
#                         # print confustion_matric with the predicted values for test and train data
#                         title_test = "[" + self.device + "] [Test Data] RandomForestClassifer"
#                         title_train ="[" + self.device + "] [Train Data] RandomForestClassifer"
                        
#                         # Store the model and results as a class variable
#                         self.dt_test_cm, self.dt_train_cm = self.iot_confusion_matrix( True, y_test, y_hat_test, title_test, y_train, y_hat_train, title_train )                        
#                         self.dt = dt

#                         print("best_estimator_:", gs.best_estimator_)
#                         print(".best_score_: ", gs.best_score_)
#                         print("score: ", gs.best_estimator_.score(self.X_test, self.y_test))
                    elif model_name == "XGBClassifier":
                        # Instantiate XGBClassifier
                        xgb = XGBClassifier()
                
                        # Fit and Predict Model
                        self.xgb_test_cm, self.xgb_train_cm, self.xgb_test_prediction, self.xgb_train_prediction = \
                            self.iot_Fit_Predict_Report(xgb, model_name, X_train_ss, X_test_ss, y_train, y_test)
                        self.xgb_model = xgb
                    elif model_name == "LGBMClassifier":
                        # Instantiate LGBMClassifier
                        lgbm = lgb.LGBMClassifier() 

                        self.xgb_test_cm, self.xgb_train_cm, self.xgb_test_prediction, self.xgb_train_prediction = \
                            self.iot_Fit_Predict_Report(lgbm, model_name, X_train_ss, X_test_ss, y_train, y_test)
                        self.lgbm_model = lgbm                   
                    else:
                        Print("Incorrect model. Refer to iot.iot_Model_")
                        
    def iot_precision(self, y, y_hat):
        '''
            Method: iot_precision
            Calculate Precision
        '''
        # Could also use confusion matrix
        y_y_hat = list(zip(y, y_hat))
        tp = sum([1 for i in y_y_hat if i[0] == 1 and i[1] == 1])
        fp = sum([1 for i in y_y_hat if i[0] == 0 and i[1] == 1])
        return tp / float(tp + fp)
    
    def iot_recall(self, y, y_hat):
        '''
            Method: iot_recall
            Calculate Recall
        '''
        y_y_hat = list(zip(y, y_hat))
        tp = sum([1 for i in y_y_hat if i[0] == 1 and i[1] == 1])
        fn = sum([1 for i in y_y_hat if i[0] == 1 and i[1] == 0])
        return tp / float(tp + fn)    
    
    def iot_accuracy(self, y, y_hat):
        '''
            Method: iot_accuracy
            Calculate Accuracy
        '''
        y_y_hat = list(zip(y, y_hat))
        tp = sum([1 for i in y_y_hat if i[0] == 1 and i[1] == 1])
        tn = sum([1 for i in y_y_hat if i[0] == 0 and i[1] == 0])
        return (tp + tn) / float(len(y_hat))
    
    def iot_f1(self, y, y_hat):
        '''
            Method: iot_f1
            Calculate F1
        '''
        precision_score = precision(y, y_hat)
        recall_score = recall(y, y_hat)
        numerator = precision_score * recall_score
        denominator = precision_score + recall_score
        return 2 * (numerator / denominator)   
  
    def accuracy(self,  confusion_matrix):
        diagonal_sum = confusion_matrix.trace()
        sum_of_all_elements = confusion_matrix.sum()
        return diagonal_sum / sum_of_all_elements 

    def recall(self, label, confusion_matrix):
        row = confusion_matrix[label, :]
        return confusion_matrix[label, label] / row.sum()
    
    def precision(self, label, confusion_matrix):
        col = confusion_matrix[:, label]
        return confusion_matrix[label, label] / col.sum()
    
    def recall_macro_average(self, confusion_matrix):
        rows, columns = confusion_matrix.shape
        sum_of_recalls = 0
        for label in range(columns):
            sum_of_recalls += self.recall(label, confusion_matrix)
        return sum_of_recalls / columns

    def iot_compare_recall_accuracy(self, test): 

        training_recall_benign = []
        training_recall_mirai = []
        training_recall_gafgyt = []
        testing_recall_benign = []
        testing_recall_mirai = []
        testing_recall_gafgyt = []      
        testing_recall_macro_average = []
        training_recall_macro_average = []
        training_accuracy = []
        testing_accuracy =[]


        for i in range(70, 100):
            print("Iteration = ",i)
            X_train, X_test, y_train, y_test = train_test_split(self.X, self.y, test_size=i/100.0)
            
            if test == "LogisticRegression":
                model = LogisticRegression(fit_intercept=False, C=1e25, solver='liblinear')
            elif test == "KNeighborsClassifier":
                model = KNeighborsClassifier(3, n_jobs=4)
                
            model = model.fit(X_train, y_train)
            
            y_hat_test = model.predict(X_test)
            y_hat_train = model.predict(X_train)
            
            cm_test = confusion_matrix(y_test, y_hat_test)
            cm_train = confusion_matrix(y_train, y_hat_train)

            for i in [0,1,2]:
                training_recall_benign.append(self.recall(i, cm_train))
                testing_recall_benign.append(self.recall(i, cm_test))  
                training_recall_mirai.append(self.recall(i, cm_train))
                testing_recall_mirai.append(self.recall(i, cm_test))                
                training_recall_mirai.append(self.recall(i, cm_train))
                testing_recall_mirai.append(self.recall(i, cm_test))                  
                training_recall_gafgyt.append(self.recall(i, cm_train))
                testing_recall_gafgyt.append(self.recall(i, cm_test))  
            testing_recall_macro_average.append(self.recall_macro_average(cm_test))
            training_recall_macro_average.append(self.recall_macro_average(cm_train))            

            training_accuracy.append(self.accuracy(cm_train))
            testing_accuracy.append(self.accuracy(cm_train))
#         # https://www.python-course.eu/confusion_matrix.php
            
#         Train and test recall_benign
        plt.scatter(list(range(0,90)), training_recall_benign, label='training_recall_benign')
        plt.scatter(list(range(0,90)), testing_recall_benign, label='testing_recall_benign')
        plt.scatter(list(range(0,90)), testing_recall_mirai, label='training_recall_mirai')
        plt.scatter(list(range(0,90)), testing_recall_mirai, label='testing_recall_mirai')
        plt.scatter(list(range(0,90)), testing_recall_gafgyt, label='training_recall_gafgyt')
        plt.scatter(list(range(0,90)), testing_recall_gafgyt, label='testing_recall_gafgyt')   
        plt.scatter(list(range(0,30)), training_accuracy, label='training_accuracy')
        plt.scatter(list(range(0,30)), testing_accuracy, label='testing_accuracy')         
        
        plt.legend()
        plt.show()

